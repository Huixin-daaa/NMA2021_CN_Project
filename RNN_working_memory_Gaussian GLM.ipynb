{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RNN_working_memory_Gaussian GLM.ipynb","provenance":[{"file_id":"https://github.com/NeuromatchAcademy/course-content/blob/master/projects/theory/RNN_working_memory.ipynb","timestamp":1625730660990}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"rAspfnJ5izdj"},"source":["import numpy as np\n","import math\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s-z_F2ARTW9C"},"source":["import os\n","\n","import torch\n","from torch import nn\n","from torch import optim\n","\n","import matplotlib as mpl\n","from matplotlib import pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FWVahTy8MA8W"},"source":["#for trial 2\n","def plot_spikes_with_prediction(\n","    input_stream, predicted_input_stream, dt, nt=50, t0=120, **kws):\n","  \"\"\"Plot actual and predicted spike counts.\n","\n","  Args:\n","    spikes (1D array): Vector of actual spike counts\n","    predicted_spikes (1D array): Vector of predicted spike counts\n","    dt (number): Duration of each time bin.\n","    nt (number): Number of time bins to plot\n","    t0 (number): Index of first time bin to plot.\n","    kws: Pass additional keyword arguments to plot()\n","\n","  \"\"\"\n","  t = np.arange(t0, t0 + nt) * dt\n","\n","  f, ax = plt.subplots()\n","  lines = ax.stem(t, input_stream[:nt], use_line_collection=True)\n","  plt.setp(lines, color=\".5\")\n","  lines[-1].set_zorder(1)\n","  kws.setdefault(\"linewidth\", 3)\n","  yhat, = ax.plot(t, predicted_input_stream[:nt], **kws)\n","  ax.set(\n","      xlabel=\"Time (s)\",\n","      ylabel=\"Input\",\n","  )\n","  ax.yaxis.set_major_locator(plt.MaxNLocator(integer=True))\n","  ax.legend([lines[0], yhat], [\"input_stream\", \"Predicted\"])\n","\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_sZUk1FEhHJo"},"source":["# Set some properties of the model. We'll store these in a dict so they're\n","# easier to pass around or save.\n","model = {}\n","\n","# properties of the recurrent pool:\n","model['N']      = 1000                 # number of neurons\n","model['g']      = 0.95                 # gain of synaptic weights in pool\n","model['sp']     = 0.25                 # fraction of weights that are nonzero\n","model['tau']    = 20                   # neural membrane time constant in ms\n","model['dt']     = 0.1                  # simulation timestep in ms\n","model['nonlin'] = lambda x: np.tanh(x) # firing rate nonlinearity for pool units\n","\n","# properties of the input layer:\n","# a note: we're going to encode the \"value\" of the input by the identity of the\n","# active input layer units. We'll use one-hot encoding: for each input step\n","# during simulation, one unit will be activated with \"firing rate\" 1, and the\n","# rest will be set to firing rate 0 (adjust gIn to change the scaling of input\n","# to the recurrent pool.)\n","# Note 1: This is just one way of setting up input- are there other approaches\n","# that would improve memory capacity?\n","# Note 2: Burn-in time is especially important if your model has g>1, in which\n","# case neurons will be spontaneously active.\n","model['nIn']    = 20                   # size of the input layer\n","model['gIn']    = 0.9                 # gain of the input weights\n","model['spIn']   = 0.05                 # sparsity of input->pool connectivity\n","model['burnIn'] = 10                   # time before input starts\n","model['durIn']  = 1                    # time for which an input is active in ms\n","model['ISI']    = 0                    # time between inputs in ms\n","model['nonlinIn'] = lambda x: x        # best to keep the input linear"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nR4Mx8tpjC0O"},"source":["# Create the synaptic weight matrix.\n","# Normalizing weights by sqrt(N*sparsity) keeps the eigenvalue spectrum\n","# invariant to the size of the population N.\n","randMat      = np.random.normal(0, 1, size=(model['N'], model['N']))\n","spMat        = np.random.uniform(0, 1, size=(model['N'], model['N'])) \\\n","                <= model['sp']\n","model['J']   = np.multiply(randMat, spMat) \\\n","                * model['g'] / math.sqrt(model['N'] * model['sp'])\n","\n","# Create the input weight matrix.\n","randMatIn    = np.random.normal(0, 1, size=(model['N'], model['nIn']))\n","spMatIn      = np.random.uniform(0, 1, size=(model['N'], model['nIn'])) \\\n","                <= model['spIn']\n","model['Jin'] = np.multiply(randMatIn, spMatIn) \\\n","                * model['gIn'] / math.sqrt(model['nIn'] * model['spIn'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d9JV0oPE67Rv"},"source":["# Define a couple helper functions for simulation.\n","\n","def step(firing_rates, input_layer, model):\n","  # The simulation function. We use Euler's method to simulate the evolution of\n","  # model neuron firing rates given the input_layer firing rates.\n","  \n","  timestep = math.exp(-model['dt']/model['tau'])\n","  vIn = np.matmul(model['J'], firing_rates) \\\n","        + np.matmul(model['Jin'], model['nonlinIn'](input_layer))\n","  updated_rates = model['nonlin'](vIn + (firing_rates - vIn) * timestep)\n","\n","  return updated_rates\n","\n","\n","def make_input(sequence_length, model):\n","  # Generates a sequence of inputs according to the parameters in model. Returns\n","  # the sequence both as a one-hot encoding and as a sequence of integer values.\n","\n","  input_stream = [0] * int(model['burnIn']/model['dt'])\n","\n","  for i in range(sequence_length):\n","    val = np.random.randint(0, model['nIn']) + 1\n","    for t in range(int(model['ISI']/model['dt'])):\n","      input_stream.append(0.0)\n","    for t in range(int(model['durIn']/model['dt'])):\n","      input_stream.append(val)\n","    \n","  input_stream = np.array(input_stream)\n","\n","  onehot = np.zeros((model['nIn']+1, input_stream.size))\n","  onehot[input_stream, np.arange(input_stream.size)] = 1.0\n","  onehot = onehot[1:,:] #还是没太明白onehot encoding？\n","  \n","\n","  return onehot, input_stream"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lfvh5rfxk4Cs"},"source":["# Look at an example input stream.\n","\n","onehot, stream = make_input(50, model)\n","print(stream) #50 total input; duration of each input is 1ms; dt = 0.1ms; 10 values for each input\n","\n","print(onehot.shape)\n","\n","fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n","omit = int(model['burnIn']/model['dt']) # don't plot the burn-in period\n","ax[0].plot(np.arange(len(stream) - omit) * model['dt'], stream[omit:]);\n","ax[0].set_xlabel('time (ms)');\n","ax[0].set_ylabel('input value');\n","\n","ax[1].imshow(onehot[:, omit:], aspect='auto');\n","ax[1].set_xlabel('time (ms)');\n","ax[1].set_ylabel('input one-hot encoding');"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mf-waHNBvHzc"},"source":["# Take a look at the eigenvalue spectrum of J.\n","w, v = np.linalg.eig(model['J'])\n","\n","fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n","showCount = 50  # portion of J to actually show (for readability)\n","h=ax[0].imshow(model['J'][:showCount,:showCount]);\n","ax[0].set_title('Sample from weight matrix J');\n","ax[0].set_xlabel('presynaptic neuron');\n","ax[0].set_ylabel('postsynaptic neuron');\n","plt.colorbar(h, ax=ax[0]);\n","\n","ax[1].plot(np.real(w),np.imag(w),'.');\n","ax[1].plot(np.sin(np.linspace(0,2*math.pi,100)),\n","           np.cos(np.linspace(0,2*math.pi,100))); # circle with radius 1\n","ax[1].set_title('Eigenvalue spectrum of J')\n","ax[1].set_xlabel('real component');\n","ax[1].set_ylabel('imaginary component');"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SZf5SO51qLGn"},"source":["# Simulate the model activity.\n","\n","# generate the input to the model\n","onehot, input_stream = make_input(10, model)\n","print(input_stream) #10 total input; duration of each input is 1ms; dt = 0.1ms; 10 values for each input\n","\n","# initialize the firing rates randomly\n","print(len(input_stream)) #200\n","firing_rates = np.zeros((model['N'], len(input_stream)))\n","firing_rates[:, 0] = np.random.uniform(0, 0.1, size=(model['N']))\n","\n","for t in range(len(input_stream)-1):\n","  firing_rates[:,t+1] = step(firing_rates[:,t], onehot[:,t], model) #update_rate based on its previous status and input\n","print(firing_rates.shape) #(1000,200) 1000 neurons, 200 time points\n","\n","fig, ax = plt.subplots(2, 1, figsize=(8, 12))\n","simulation_time = np.arange(len(input_stream))*model['dt'] - model['burnIn']\n","ax[0].plot(simulation_time, input_stream);\n","ax[0].set_xlabel('Time (ms)');\n","ax[0].set_ylabel('Input value');\n","\n","extents = [simulation_time[0],simulation_time[-1], 0, model['N']]\n","ax[1].imshow(firing_rates, aspect='auto', extent=extents);\n","ax[1].set_xlabel('Time (ms)');\n","ax[1].set_ylabel('Neurons');\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aUfns5AbwGJb"},"source":["Now: can you decode the model's input history from its firing rates?"]},{"cell_type":"code","metadata":{"id":"3GigKre_Qnbo"},"source":["#INPUT: print(firing_rates.shape) \n","#(1000,200) 1000 neurons, 200 time points\n","#OUTPUT: onehot, input_stream = make_input(10, model)\n","#print(input_stream) 1d array\n","#10 total input; duration of each input is 1ms; dt = 0.1ms; 10 values for each input\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ayAwGdEo7g2u"},"source":["#Trial 2: Linear-Gaussian GLM\n","def make_design_matrix(resp, d=5):\n","  \"\"\"Create time-lag design matrix from stimulus intensity vector.\n","  Args:\n","    stim (1D array): Stimulus intensity at each time point. #response: 2D matrix\n","    d (number): Number of time lags to use.\n","  Returns\n","    X (2D array): GLM design matrix with shape T, d\n","  \"\"\"\n","  # Create version of stimulus vector with zeros before onset\n","  padded_resp = np.hstack([resp, np.zeros((1000, d - 1))])\n","\n","  # Construct a matrix where each row has the d frames of\n","  # the stimulus proceeding and including timepoint t\n","  T = len(input_stream)  # Total number of timepoints (hint: number of stimulus frames)\n","  X = np.zeros((T, d * model['N']))\n","  for t in range(T):\n","      X[t,:] = padded_resp[:, t:t + d].flatten()\n","\n","  return X\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tmVoOinlH5tM","outputId":"7eb5fcb7-3c44-482a-e44a-c09cab828e0d"},"source":["# Build the full design matrix\n","y = input_stream\n","constant = np.ones_like(y)\n","X = np.column_stack([constant, make_design_matrix(firing_rates)])\n","print(X.shape)\n","\n","# Get the MLE weights for the LG model\n","theta = np.linalg.inv(X.T @ X) @ X.T @ y\n","theta_lg = theta[1:]\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(200, 20001)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Z8KCeLaNJAB1"},"source":["predicted_input_stream = X @ theta"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BR0l0Y7-TXMH"},"source":["fig, ax = plt.subplots(2, 1, figsize=(8, 12))\n","simulation_time = np.arange(len(input_stream))*model['dt'] - model['burnIn']\n","ax[0].plot(simulation_time, input_stream);\n","ax[0].set_xlabel('Time (ms)');\n","ax[0].set_ylabel('Input value');\n","\n","ax[1].plot(simulation_time, predicted_input_stream);\n","ax[1].set_xlabel('Time (ms)');\n","ax[1].set_ylabel('Predicted input value');"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YD-0MTfxWSO3"},"source":["mse = np.mean((input_stream - predicted_input_stream)**2)\n","print(mse)"],"execution_count":null,"outputs":[]}]}